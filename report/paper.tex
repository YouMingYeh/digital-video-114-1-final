\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}

\begin{document}

\title{Depth-Guided Video Preprocessing for Bandwidth-Constrained Streaming\thanks{Code available at: \url{https://github.com/YouMingYeh/digital-video-114-1-final}}}

\author{
\IEEEauthorblockN{Bo-Ru Chen}
\IEEEauthorblockA{R14922158\\
National Taiwan University}
\and
\IEEEauthorblockN{You-Ming Yeh}
\IEEEauthorblockA{R14944035\\
National Taiwan University}
}

\maketitle

\begin{abstract}
RGB-D sensors enable depth-aware quality allocation in video compression, but whether preprocessing background regions actually improves compression remains unclear. We investigate this question through systematic experiments comparing bilateral and Gaussian blur preprocessing against standard H.264 encoding. Our evaluation spans multiple metrics: BD-Rate for compression efficiency, PSNR and SSIM for objective quality, VMAF for perceptual quality, and a weighted ROI-PSNR that prioritizes foreground regions. The results reveal a nuanced picture: while BD-Rate analysis confirms preprocessing hurts overall efficiency by 18--53\%, matched-size comparisons show preprocessing improves foreground quality by 0.2--0.5 dB at low bitrates below 1 MB per 5 seconds of 2K content. Above 2 MB, standard encoding wins across all metrics. These findings suggest depth-guided preprocessing as a viable strategy specifically for bandwidth-constrained scenarios like mobile streaming or video conferencing, where foreground quality matters most.
\end{abstract}

\begin{IEEEkeywords}
RGBD video compression, depth-guided preprocessing, perceptual quality, region-of-interest encoding
\end{IEEEkeywords}

\section{Introduction}

The proliferation of RGB-D sensors in smartphones, tablets, and AR/VR headsets has created new opportunities for content-aware video compression. Depth information provides a natural saliency signal: objects closer to the camera typically correspond to subjects of interest, while distant regions often constitute less important background. This observation motivates a straightforward hypothesis---can we improve perceived quality by selectively degrading background regions before compression?

The intuition behind this approach seems compelling. By blurring or smoothing background regions, we reduce high-frequency content that consumes encoding bits. The encoder can then allocate more bits to foreground regions, potentially improving quality where it matters most. However, this reasoning overlooks a critical issue: modern video encoders already perform sophisticated rate-distortion optimization. Preprocessing may simply destroy information that the encoder could have efficiently represented.

This paper investigates whether depth-guided preprocessing actually helps. We implement two preprocessing methods---bilateral filtering and Gaussian blur---and compare against standard H.264 encoding across a comprehensive set of evaluation metrics. Our experiments reveal that the answer depends critically on the target bitrate, with preprocessing showing benefits only under severe bandwidth constraints.

\section{Related Work}

\subsection{Region-of-Interest Video Coding}

ROI-based coding has been extensively studied in video compression standards. H.264/AVC supports flexible macroblock-level QP adjustment \cite{h264}, enabling quality differentiation across frame regions. The concept was formalized in HEVC through tiles and wavefront parallel processing \cite{hevc}, though these features target parallelism rather than quality allocation.

More sophisticated approaches use eye-tracking data to guide quality allocation. Hadizadeh et al. \cite{eyetrack} demonstrated that saliency-based bit allocation can reduce bitrate by 30\% at equivalent perceptual quality. Our work differs by using depth as the saliency signal, which is available from commodity sensors without requiring eye-tracking equipment.

\subsection{3D Video Compression}

The 3D-HEVC extension \cite{3dhevc} introduced depth-based coding tools including view synthesis optimization and depth intra-coding modes. While these tools target multiview scenarios, the underlying principle of exploiting depth information aligns with our approach. However, 3D-HEVC operates at the encoder level, whereas our preprocessing approach works with any standard encoder.

\subsection{Perceptual Video Quality}

BD-Rate \cite{bdrate} remains the standard metric for codec comparison, measuring bitrate differences at equivalent PSNR. However, PSNR correlates poorly with human perception for certain distortion types. VMAF \cite{vmaf} addresses this limitation through machine learning trained on subjective quality data, though it evaluates whole-frame quality rather than region-specific quality.

\section{Methodology}

\subsection{Depth-Guided Preprocessing}

Given an RGB frame $I$ and corresponding depth map $D$, we first compute an importance map $M$ where values closer to 1 indicate foreground:
\begin{equation}
M(x,y) = 1 - \frac{D(x,y) - D_{min}}{D_{max} - D_{min}}
\end{equation}

The preprocessed frame blends original and filtered content:
\begin{equation}
I'(x,y) = M(x,y) \cdot I(x,y) + (1-M(x,y)) \cdot F(I)(x,y)
\end{equation}
where $F$ denotes the filtering operation. We evaluate two choices:

\textbf{Bilateral filter} ($d=15$, $\sigma_{color}=\sigma_{space}=150$): Smooths background while preserving edges, maintaining structural coherence at region boundaries.

\textbf{Gaussian blur} ($k=15$): Aggressive smoothing that maximizes bit savings but introduces visible blur in background regions.

\subsection{Evaluation Framework}

We evaluate using multiple complementary metrics:

\textbf{BD-Rate}: Standard compression efficiency metric computed via Bjontegaard delta \cite{bdrate} from R-D curves at CRF values 18, 23, 28, 33, 38, 43.

\textbf{Matched-size comparison}: Binary search on CRF to achieve target file sizes (0.3, 0.5, 1.0, 2.0, 3.0 MB), then measure quality at each size.

\textbf{ROI-PSNR}: PSNR computed only over foreground pixels ($M > 0.5$), measuring quality where users focus attention.

\textbf{Weighted PSNR}: Full-frame PSNR with foreground pixels weighted $3\times$ higher than background, balancing both regions.

\textbf{VMAF}: Netflix's perceptual quality model \cite{vmaf} for whole-frame perceptual assessment.

\section{Experimental Setup}

\textbf{Dataset}: We use the Mandelbulb 3D fractal dataset rendered at 2048$\times$2048 resolution, 30 fps, with corresponding depth maps. Two 5-second segments (150 frames each) capture different motion characteristics: \textit{rotation} with stable depth distribution, and \textit{zoom} with dynamically changing depth.

\textbf{Encoder}: H.264 via FFmpeg's libx264 with \texttt{medium} preset and \texttt{yuv420p} pixel format. CRF mode ensures consistent quality targeting.

\textbf{Implementation}: Python with OpenCV for preprocessing, NumPy for metric computation, and FFmpeg for encoding and VMAF calculation.

\section{Results}

\subsection{BD-Rate Analysis}

Fig.~\ref{fig:rd} shows rate-distortion curves for all methods. Preprocessing shifts curves rightward, indicating worse efficiency at equivalent quality. Table~\ref{tab:bdrate} quantifies this through BD-Rate:

\begin{figure}[htbp]
\centering
\includegraphics[width=\columnwidth]{fig1_rd_curves.png}
\caption{Rate-distortion curves comparing baseline H.264 against depth-guided preprocessing. Both bilateral and blur methods require higher bitrates to achieve equivalent PSNR.}
\label{fig:rd}
\end{figure}

\begin{table}[htbp]
\caption{BD-Rate vs. Baseline (positive indicates worse efficiency)}
\label{tab:bdrate}
\centering
\begin{tabular}{@{}lcc@{}}
\toprule
Segment & Bilateral & Gaussian Blur \\
\midrule
Rotation & +18.3\% & +31.4\% \\
Zoom & +18.0\% & +53.8\% \\
\bottomrule
\end{tabular}
\end{table}

The bilateral filter shows consistent 18\% overhead across both segments. Gaussian blur performs significantly worse, particularly on the zoom segment where dynamic depth changes amplify preprocessing artifacts.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\columnwidth]{fig2_bd_rate.png}
\caption{BD-Rate comparison showing efficiency loss from preprocessing. Lower is better; both methods increase required bitrate.}
\label{fig:bdrate}
\end{figure}

\subsection{Quality at Matched File Sizes}

BD-Rate measures efficiency, but practical applications often have fixed bandwidth budgets. Table~\ref{tab:roi} shows ROI-PSNR when all methods are constrained to identical file sizes:

\begin{table}[htbp]
\caption{ROI-PSNR (dB) at Matched File Sizes}
\label{tab:roi}
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
Target & Baseline & Bilateral & Blur & Best $\Delta$ \\
\midrule
0.3 MB & 17.17 & 17.46 & \textbf{17.71} & +0.54 \\
0.5 MB & 18.53 & \textbf{18.74} & 18.61 & +0.21 \\
1.0 MB & 20.25 & \textbf{20.36} & 19.72 & +0.11 \\
2.0 MB & \textbf{21.93} & 21.77 & 20.42 & --- \\
3.0 MB & \textbf{22.84} & 22.47 & 20.67 & --- \\
\bottomrule
\end{tabular}
\end{table}

At low bitrates (0.3--1.0 MB), preprocessing improves foreground quality by 0.1--0.5 dB. The crossover occurs between 1--2 MB, above which baseline encoding wins. Table~\ref{tab:weighted} confirms this pattern with weighted PSNR.

\begin{table}[htbp]
\caption{Weighted PSNR (foreground $3\times$ weight) at Matched Sizes}
\label{tab:weighted}
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
Target & Baseline & Bilateral & Blur & Best $\Delta$ \\
\midrule
0.3 MB & 22.88 & 23.17 & \textbf{23.39} & +0.51 \\
0.5 MB & 24.25 & \textbf{24.47} & 24.29 & +0.22 \\
1.0 MB & 25.98 & \textbf{26.08} & 25.41 & +0.10 \\
2.0 MB & \textbf{27.66} & 27.50 & 26.09 & --- \\
3.0 MB & \textbf{28.58} & 28.21 & 26.34 & --- \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Background Quality Trade-off}

Foreground gains come at background cost. Table~\ref{tab:bg} shows background PSNR ($M < 0.3$):

\begin{table}[htbp]
\caption{Background PSNR (dB) at Matched Sizes}
\label{tab:bg}
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Target & Baseline & Bilateral & Blur \\
\midrule
0.3 MB & 41.41 & 41.77 & 39.40 \\
0.5 MB & 43.71 & 43.99 & 40.16 \\
1.0 MB & 46.45 & 46.21 & 40.81 \\
\bottomrule
\end{tabular}
\end{table}

Bilateral filtering maintains background quality comparable to baseline. Gaussian blur sacrifices 3--6 dB, creating visible degradation.

\subsection{Perceptual Quality}

VMAF evaluates whole-frame perceptual quality, penalizing any visible artifacts. Table~\ref{tab:vmaf} shows baseline winning at all bitrates:

\begin{table}[htbp]
\caption{VMAF Scores at Matched File Sizes}
\label{tab:vmaf}
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Target & Baseline & Blur & $\Delta$ \\
\midrule
0.5 MB & \textbf{37.26} & 26.40 & $-10.9$ \\
1.0 MB & \textbf{62.74} & 45.09 & $-17.7$ \\
3.0 MB & \textbf{81.42} & 53.59 & $-27.8$ \\
\bottomrule
\end{tabular}
\end{table}

The VMAF penalty increases with bitrate because preprocessing artifacts become more noticeable against the higher baseline quality.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\columnwidth]{fig4_tradeoff.png}
\caption{Size reduction vs. quality trade-off at CRF=28. Points below the horizontal axis indicate quality loss; rightward indicates size reduction.}
\label{fig:tradeoff}
\end{figure}

\section{Discussion}

\subsection{The Crossover Point}

Our results identify a bitrate-dependent crossover around 400--800 kbps (1--2 MB per 5 seconds at 2K resolution). Below this threshold, preprocessing helps because encoders operating at severe rate constraints cannot preserve all spatial detail. By pre-degrading background regions, we effectively guide the encoder's bit allocation toward foreground content.

Above the crossover, encoders have sufficient capacity to represent the full frame adequately. Preprocessing then destroys recoverable information---the encoder could have efficiently coded the original background detail, but that information is permanently lost through blur.

\subsection{Bilateral vs. Gaussian Blur}

Bilateral filtering emerges as the safer choice: it provides consistent 0.1--0.2 dB foreground improvement at low bitrates while maintaining background quality. Its edge-preserving properties prevent the harsh transitions that make Gaussian blur visually objectionable.

Gaussian blur offers larger foreground gains (+0.5 dB at 0.3 MB) but creates severe background degradation (3--6 dB loss). This aggressive approach may be appropriate only when background quality is genuinely unimportant---a narrow use case.

\subsection{Metric Selection}

The choice of evaluation metric significantly influences conclusions. BD-Rate and VMAF favor baseline encoding because they treat all pixels equally. ROI-PSNR and weighted PSNR reveal foreground benefits invisible to whole-frame metrics.

This highlights the importance of application-specific evaluation. Video conferencing systems should weight face regions heavily; AR applications might prioritize near-field objects; general streaming requires whole-frame quality. No single metric captures all use cases.

\subsection{Limitations}

Our experiments use synthetic data with procedurally generated depth. Real-world RGB-D video from consumer sensors introduces depth estimation errors, temporal inconsistency, and edge artifacts that may affect preprocessing quality. Additionally, our preprocessing operates independently per frame; temporal filtering could improve consistency but adds complexity.

\section{Conclusion}

Depth-guided preprocessing does not universally improve video compression. BD-Rate analysis confirms an 18--53\% efficiency penalty. However, at constrained bitrates below approximately 1 MB per 5 seconds of 2K content, preprocessing with bilateral filtering improves foreground quality by 0.2--0.5 dB at matched file sizes.

These findings suggest practical applications in bandwidth-constrained scenarios. Mobile video conferencing, low-bandwidth streaming, and similar applications where foreground quality matters most could benefit from depth-guided preprocessing. High-quality streaming services should use standard encoding.

An adaptive approach selecting based on target bitrate represents the optimal strategy: enable preprocessing below the crossover threshold, disable it above.

\begin{thebibliography}{00}
\bibitem{h264} T. Wiegand, G. J. Sullivan, G. Bjontegaard, and A. Luthra, ``Overview of the H.264/AVC video coding standard,'' IEEE Trans. Circuits Syst. Video Technol., vol. 13, no. 7, pp. 560--576, Jul. 2003.
\bibitem{hevc} G. J. Sullivan, J.-R. Ohm, W.-J. Han, and T. Wiegand, ``Overview of the High Efficiency Video Coding (HEVC) standard,'' IEEE Trans. Circuits Syst. Video Technol., vol. 22, no. 12, pp. 1649--1668, Dec. 2012.
\bibitem{eyetrack} H. Hadizadeh and I. V. Bajic, ``Saliency-aware video compression,'' IEEE Trans. Image Process., vol. 23, no. 1, pp. 19--33, Jan. 2014.
\bibitem{3dhevc} G. Tech, Y. Chen, K. Mueller, J.-R. Ohm, A. Vetro, and Y.-K. Wang, ``Overview of the multiview and 3D extensions of High Efficiency Video Coding,'' IEEE Trans. Circuits Syst. Video Technol., vol. 26, no. 1, pp. 35--49, Jan. 2016.
\bibitem{bdrate} G. Bjontegaard, ``Calculation of average PSNR differences between RD-curves,'' ITU-T SG16 Doc. VCEG-M33, Apr. 2001.
\bibitem{vmaf} Z. Li, A. Aaron, I. Katsavounidis, A. Moorthy, and M. Manohara, ``Toward a practical perceptual video quality metric,'' Netflix Tech. Blog, Jun. 2016.
\end{thebibliography}

\end{document}
